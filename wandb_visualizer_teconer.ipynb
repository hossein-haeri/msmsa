{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of runs: 28\n"
     ]
    }
   ],
   "source": [
    "# Initialize the API\n",
    "api = wandb.Api()\n",
    "\n",
    "# Specify your project details\n",
    "entity = \"haeri-hsn\"  # Replace with your wandb entity\n",
    "project = \"stream_learning\"  # Replace with your wandb project name\n",
    "\n",
    "# Define filters\n",
    "filters = {\n",
    "    'state': 'finished',  # Only fetch finished runs\n",
    "    'tags': {'$in': ['teconer_final_v3']},  # Runs containing a specific tag msmsa_horizon_analysis_melbourne_housing \\ msmsa_anchor_analysis_melbourne_housing\n",
    "    # 'CreatedAt': {'$gt': '2024-7-9'}  # Only fetch runs created after a specific date\n",
    "}\n",
    "\n",
    "# Query runs with filters\n",
    "runs = api.runs(f\"{entity}/{project}\", filters=filters)\n",
    "\n",
    "# print number of runs\n",
    "print(f\"Number of runs: {len(runs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['name', 'seed', 'tags', 'dataset', 'epsilon', 'wandb_log',\n",
      "       'base_learner', 'online_model', 'RMSE', '_timestamp', 'MAE', 'TMI',\n",
      "       'learning_model', '_wandb', 'training_size_log', '_runtime',\n",
      "       'average_records_per_trip', 'R2', '_step', 'average_preview_records',\n",
      "       'average_training_size', 'preview_window'],\n",
      "      dtype='object')\n",
      "['teconer_helsinki_jan2018' 'teconer_helsinki_jan2018_100K']\n",
      "[ 5. 10. 30.  1.]\n",
      "60\n",
      "600\n",
      "300\n",
      "1800\n"
     ]
    }
   ],
   "source": [
    "# Extract data from each run\n",
    "summary_list = []\n",
    "config_list = []\n",
    "name_list = []\n",
    "for run in runs:\n",
    "    # run.summary contains the output of the training\n",
    "    summary_list.append(run.summary._json_dict)\n",
    "\n",
    "    # run.config contains the hyperparameters\n",
    "    config_list.append({k: v for k, v in run.config.items() if not k.startswith('_')})\n",
    "\n",
    "    # run.name is the name of the run.\n",
    "    name_list.append(run.name)\n",
    "\n",
    "# Convert to DataFrame\n",
    "summary_df = pd.DataFrame.from_records(summary_list)\n",
    "config_df = pd.DataFrame.from_records(config_list)\n",
    "name_df = pd.DataFrame({'name': name_list})\n",
    "\n",
    "# Combine all parts into one DataFrame\n",
    "df = pd.concat([name_df, config_df, summary_df], axis=1)\n",
    "# remove the columns that are repeated\n",
    "df['preview_window'] = df['preview_window'].astype('float')/60\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "# change the name of the metrics and remove metric_ from the name\n",
    "df = df.rename(columns=lambda x: x.replace(\"metric_\", \"\"))\n",
    "# Display the DataFrame\n",
    "print(df.columns)\n",
    "df = df.dropna(subset=['preview_window'])\n",
    "# print the values of the dataset (unique values)\n",
    "print(df['dataset'].unique())\n",
    "print(df['preview_window'].unique())\n",
    "# drop with the preview_window = nan\n",
    "\n",
    "\n",
    "list_of_files = ['Teconer_results/firm-elevator-1052.pkl', 'Teconer_results/jumping-gorge-1050.pkl', 'Teconer_results/vague-wind-1050.pkl', 'Teconer_results/dry-sky-1049.pkl']\n",
    "\n",
    "for file_name in list_of_files:\n",
    "    _ , summary = pd.read_pickle(file_name)\n",
    "    new_row = pd.DataFrame({'R2': [summary['metric_R2']], 'RMSE': [summary['metric_RMSE']], 'MAE': [summary['metric_MAE']], 'dataset': [summary['dataset']], 'preview_window': [summary['preview_window']/60], 'epsilon': [.9]})\n",
    "    # Adding a new row to the DataFrame\n",
    "    # print(summary['preview_window'])\n",
    "    df = pd.concat([df, new_row], ignore_index=True)\n",
    "\n",
    "# print(summary1.keys())  \n",
    "\n",
    "# two rows have the same dataset and preview_window and epsilon remove the one with the lower R2\n",
    "df = df.sort_values('R2', ascending=False).drop_duplicates(['dataset', 'preview_window', 'epsilon'], keep='first')\n",
    "# print the values of the dataset (unique values)\n",
    "\n",
    "# print unique values of the preview_window\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAE, RMSE, R2 Barplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95 0.55 0.7 ]\n",
      "[ 1.  5. 10. 30.]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "plt.close('all')\n",
    "# make defaul font of the plots arial\n",
    "plt.rcParams['font.sans-serif'] = \"Arial\"\n",
    "plt.rcParams['font.family'] = \"sans-serif\"\n",
    "# make the font size 12\n",
    "plt.rcParams.update({'font.size': 13})\n",
    "\n",
    "# datasets = list(df['dataset'].unique())\n",
    "datasets = ['teconer_helsinki_jan2018_100K']\n",
    "\n",
    "for dataset in datasets:\n",
    "    df_ = df[(df['dataset'] == dataset)]\n",
    "    print(df_['epsilon'].unique())\n",
    "    print(df_['preview_window'].unique())\n",
    "    f, axs = plt.subplots(1, 3, figsize=(11, 5))\n",
    "    for i, metric in enumerate(['R2', 'RMSE', 'MAE']):\n",
    "        # plot barplot of R2 scores for different epsilon values and different preview durations\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "        # Try using .loc[row_indexer,col_indexer] = value instead\n",
    "        sns.barplot(data=df_, x=\"epsilon\", y=metric, hue=\"preview_window\", errorbar=\"sd\", palette=\"coolwarm\", ax=axs[i])\n",
    "        axs[i].set_xlabel(\"epsilon\")\n",
    "        axs[i].set_ylabel(metric)\n",
    "        # rename legend title\n",
    "        if i == 1:\n",
    "            axs[i].legend(title=\"Preview [min]\", ncol=df_['preview_window'].nunique(), loc='upper center', bbox_to_anchor=(0.5, 1.3))\n",
    "        else:\n",
    "            axs[i].get_legend().remove()\n",
    "        \n",
    "        if metric == 'R2':\n",
    "            axs[i].set_ylim(0, 1)\n",
    "        if metric == 'RMSE':\n",
    "            axs[i].set_ylim(0, .14)\n",
    "        if metric == 'MAE':\n",
    "            axs[i].set_ylim(0, .09)\n",
    "        # print(df_.groupby(['epsilon', 'preview_window'])[metric].mean())\n",
    "        # add plot title below the axis\n",
    "\n",
    "\n",
    "    # f.set_size_inches(12, 5)\n",
    "    # f.suptitle(dataset)\n",
    "    # increase the space between the plots\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.5, top=0.80, bottom=0.15, left=0.07, right=.98)\n",
    "    # plt.tight_layout()\n",
    "    # save to \\plots folder\n",
    "    plt.savefig(f\"teconer_metrics_{dataset}.pdf\")\n",
    "    \n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "plt.close('all')\n",
    "\n",
    "\n",
    "# datasets = list(df['dataset'].unique())\n",
    "datasets = ['teconer_helsinki_jan2018']\n",
    "\n",
    "for dataset in datasets:\n",
    "    df_ = df[(df['dataset'] == dataset)]\n",
    "    # f, axs = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    \n",
    "    for i, metric in enumerate(['R2', 'RMSE', 'MAE']):\n",
    "        plt.figure(dataset, figsize=(5, 6))\n",
    "        # plot barplot of R2 scores for different epsilon values and different preview durations\n",
    "        sns.set_theme(style=\"whitegrid\")\n",
    "        # Try using .loc[row_indexer,col_indexer] = value instead\n",
    "        sns.barplot(data=df_, x=\"epsilon\", y=metric, hue=\"preview_window\", errorbar=\"sd\", palette=\"coolwarm\")\n",
    "        plt.xlabel(\"epsilon\")\n",
    "        plt.ylabel(metric)\n",
    "        # rename legend title\n",
    "        # if i == 1:\n",
    "        plt.legend(title=\"Preview [min]\", ncol=df_['preview_window'].nunique(), loc='upper center', bbox_to_anchor=(0.5, 1.3))\n",
    "        # else:\n",
    "            # axs[i].get_legend().remove()\n",
    "        \n",
    "    # # f.set_size_inches(12, 5)\n",
    "    # # f.suptitle(dataset)\n",
    "    # # increase the space between the plots\n",
    "    # plt.subplots_adjust(wspace=0.5, hspace=0.5, top=0.80, bottom=0.2)\n",
    "        plt.tight_layout()\n",
    "        # save to \\plots folder\n",
    "        plt.savefig(f\"teconer_{dataset}_{metric}.svg\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preview_window                  1.0     5.0     10.0     30.0\n",
      "dataset                                                      \n",
      "teconer_helsinki_jan2018       52.04  244.44  458.18  1097.23\n",
      "teconer_helsinki_jan2018_100K   3.77   14.26   26.18    60.28\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "\n",
    "# print average_ahead_records for each dataset, and preview_duration in a table\n",
    "df_ = df.groupby(['dataset', 'preview_window'])['average_preview_records'].mean().reset_index()\n",
    "df_ = df_.pivot(index='dataset', columns='preview_window', values='average_preview_records')\n",
    "df_ = df_.fillna(0)\n",
    "# df_ = df_.sort_values(by='dataset', ascending=False)\n",
    "# sort df_ based on the dataset names (given in the list)\n",
    "# df_ = df_.reindex(['Teconer_Jan_10K', 'Teconer_Jan_100K', 'Teconer_Jan_1M','Teconer_Downtown_10K', 'Teconer_Downtown_100K', 'Teconer_Downtown_1M'])\n",
    "df_ = df_.round(2)\n",
    "sns.heatmap(df_, annot=True, cmap=\"coolwarm\", fmt=\".2f\", cbar=False)\n",
    "plt.title('Average number of queried preview points')\n",
    "plt.xlabel('Preview [min]')\n",
    "plt.ylabel('Dataset')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# print df \n",
    "print(df_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size       100K    10K      1M\n",
      "location                      \n",
      "Jan 2018  95.88  11.25  956.94\n",
      "Downtown  20.28   2.93  200.46\n"
     ]
    }
   ],
   "source": [
    "# make a column 'Downtown' and 'Jan 2018' based on the dataset name\n",
    "df['location'] = df['dataset'].apply(lambda x: 'Downtown' if 'Downtown' in x else 'Jan 2018')\n",
    "\n",
    "# also make a column '10K', '100K', '1M' based on the dataset name\n",
    "df['size'] = df['dataset'].apply(lambda x: '10K' if '10K' in x else ('100K' if '100K' in x else '1M'))\n",
    "\n",
    "# plot a heatmap of average trip duration for different size values and location\n",
    "df_ = df.groupby(['location', 'size'])['average_records_per_trip'].mean().reset_index()\n",
    "df_ = df_.pivot(index='location', columns='size', values='average_records_per_trip')\n",
    "df_ = df_.fillna(0)\n",
    "df_ = df_.sort_values(by='location', ascending=False)\n",
    "df_ = df_.round(2)\n",
    "sns.heatmap(df_, annot=True, cmap=\"coolwarm\", fmt=\".2f\", cbar=False)\n",
    "plt.title('Average records per trip')\n",
    "plt.xlabel('Number of Samples in Dataset')\n",
    "plt.ylabel('')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# print the values in a table\n",
    "print(df_)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
